{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This file is used to train and test the model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-07-02T02:27:33.247848Z",
     "end_time": "2023-07-02T02:27:33.329512Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sc_model import SC_LSTM as Model"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Device init"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul  2 02:27:33 2023       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 530.41.03              Driver Version: 530.41.03    CUDA Version: 12.1     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce GTX 1650 Ti      Off| 00000000:01:00.0  On |                  N/A |\r\n",
      "| N/A   48C    P0               16W /  N/A|    839MiB /  4096MiB |     21%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A       523      G   /usr/bin/sddm-greeter                        62MiB |\r\n",
      "|    0   N/A  N/A       570      G   /usr/lib/Xorg                               423MiB |\r\n",
      "|    0   N/A  N/A       655      G   /usr/bin/kwalletd5                            1MiB |\r\n",
      "|    0   N/A  N/A       744      G   /usr/bin/ksmserver                            1MiB |\r\n",
      "|    0   N/A  N/A       746      G   /usr/bin/kded5                                1MiB |\r\n",
      "|    0   N/A  N/A       749      G   /usr/bin/kwin_x11                            83MiB |\r\n",
      "|    0   N/A  N/A       771      G   /usr/bin/plasmashell                         66MiB |\r\n",
      "|    0   N/A  N/A       803      G   ...b/polkit-kde-authentication-agent-1        1MiB |\r\n",
      "|    0   N/A  N/A       805      G   /usr/lib/xdg-desktop-portal-kde               1MiB |\r\n",
      "|    0   N/A  N/A       921      G   /usr/lib/kdeconnectd                          1MiB |\r\n",
      "|    0   N/A  N/A       924      G   /usr/bin/latte-dock                          10MiB |\r\n",
      "|    0   N/A  N/A       927      G   /usr/bin/telegram-desktop                     2MiB |\r\n",
      "|    0   N/A  N/A       932      G   /usr/bin/kaccess                              1MiB |\r\n",
      "|    0   N/A  N/A       940      G   /usr/lib/DiscoverNotifier                     1MiB |\r\n",
      "|    0   N/A  N/A       947      G   /usr/bin/kmix                                15MiB |\r\n",
      "|    0   N/A  N/A       953      G   /usr/bin/kalendarac                           1MiB |\r\n",
      "|    0   N/A  N/A      1202      G   /usr/bin/ktorrent                             1MiB |\r\n",
      "|    0   N/A  N/A      1230      G   /usr/bin/yakuake                              1MiB |\r\n",
      "|    0   N/A  N/A      1391      G   ...68429089,9606185862118792097,131072       36MiB |\r\n",
      "|    0   N/A  N/A      1800      G   ...,WinRetrieveSuggestionsOnlyOnDemand       70MiB |\r\n",
      "|    0   N/A  N/A      1993      G   ...bin/plasma-browser-integration-host        1MiB |\r\n",
      "|    0   N/A  N/A     28524      G   ...ures=SpareRendererForSitePerProcess        7MiB |\r\n",
      "|    0   N/A  N/A     45503      G   /usr/lib/baloorunner                          1MiB |\r\n",
      "|    0   N/A  N/A     45543      G   /usr/bin/konsole                              1MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "NVIDIA GeForce GTX 1650 Ti\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type == 'cuda':\n",
    "    !nvidia-smi\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print(\"No GPU :(\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-02T02:27:33.263591Z",
     "end_time": "2023-07-02T02:27:33.462764Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-02T02:27:33.462471Z",
     "end_time": "2023-07-02T02:27:33.503298Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "     Label Number  Duration  Importance Start Time        Date\n0               3        75           1       6:30  22/06/2023\n1               5        90           2       8:15  22/06/2023\n2               0        30           0      10:00  22/06/2023\n3               1        30           1      10:45  22/06/2023\n4               6        15           0      11:30  22/06/2023\n..            ...       ...         ...        ...         ...\n967             4        90           2      18:15  01/09/2023\n968             1        30           1      19:30  01/09/2023\n969             6        45           0      20:45  01/09/2023\n970             3        45           1      22:00  01/09/2023\n971             5       120           3      23:15  01/09/2023\n\n[972 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label Number</th>\n      <th>Duration</th>\n      <th>Importance</th>\n      <th>Start Time</th>\n      <th>Date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>75</td>\n      <td>1</td>\n      <td>6:30</td>\n      <td>22/06/2023</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>90</td>\n      <td>2</td>\n      <td>8:15</td>\n      <td>22/06/2023</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>30</td>\n      <td>0</td>\n      <td>10:00</td>\n      <td>22/06/2023</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>30</td>\n      <td>1</td>\n      <td>10:45</td>\n      <td>22/06/2023</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>15</td>\n      <td>0</td>\n      <td>11:30</td>\n      <td>22/06/2023</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>967</th>\n      <td>4</td>\n      <td>90</td>\n      <td>2</td>\n      <td>18:15</td>\n      <td>01/09/2023</td>\n    </tr>\n    <tr>\n      <th>968</th>\n      <td>1</td>\n      <td>30</td>\n      <td>1</td>\n      <td>19:30</td>\n      <td>01/09/2023</td>\n    </tr>\n    <tr>\n      <th>969</th>\n      <td>6</td>\n      <td>45</td>\n      <td>0</td>\n      <td>20:45</td>\n      <td>01/09/2023</td>\n    </tr>\n    <tr>\n      <th>970</th>\n      <td>3</td>\n      <td>45</td>\n      <td>1</td>\n      <td>22:00</td>\n      <td>01/09/2023</td>\n    </tr>\n    <tr>\n      <th>971</th>\n      <td>5</td>\n      <td>120</td>\n      <td>3</td>\n      <td>23:15</td>\n      <td>01/09/2023</td>\n    </tr>\n  </tbody>\n</table>\n<p>972 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Data.Preprocessor import Preprocessor\n",
    "\n",
    "preproc = Preprocessor()\n",
    "\n",
    "data = pd.read_csv('../Data/schedule_v3.csv')\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-02T02:27:33.503181Z",
     "end_time": "2023-07-02T02:27:33.558301Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "input_data, type_vector, output_vector = preproc.preprocess(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-02T02:27:33.528917Z",
     "end_time": "2023-07-02T02:27:33.558479Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Normalize input data\n",
    "scaler = MinMaxScaler()\n",
    "input_data = scaler.fit_transform(input_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-02T02:27:33.529001Z",
     "end_time": "2023-07-02T02:27:33.569349Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ScheduleDataset(Dataset):\n",
    "    def __init__(self, input_data, type_vector, output_vector, transform=None):\n",
    "        self.input_data = input_data\n",
    "        self.type_vector = type_vector\n",
    "        self.output_vector = output_vector\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_data[idx], self.type_vector[idx], self.output_vector[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-02T02:27:33.569180Z",
     "end_time": "2023-07-02T02:27:33.569471Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "dataset = ScheduleDataset(input_data, type_vector, output_vector)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-02T02:27:33.569207Z",
     "end_time": "2023-07-02T02:27:33.577344Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create dataloaders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(dataset_size * 0.8)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# also conver\n",
    "train_dataloader = torch.utils.data.DataLoader2(train_dataset, batch_size=batch_size)\n",
    "valid_dataloader = torch.utils.data.DataLoader2(test_dataset, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-02T02:27:33.578605Z",
     "end_time": "2023-07-02T02:27:33.642046Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create free time slots generator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 2)\n",
      "(13, 2)\n",
      "(13, 2)\n",
      "(13, 2)\n",
      "(13, 2)\n",
      "(13, 2)\n",
      "(13, 2)\n",
      "(13, 2)\n",
      "(13, 2)\n",
      "(13, 2)\n",
      "(13, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "(10, 2)\n",
      "(10, 2)\n",
      "(10, 2)\n",
      "(10, 2)\n",
      "(10, 2)\n",
      "(10, 2)\n",
      "(10, 2)\n",
      "(10, 2)\n",
      "(10, 2)\n",
      "(10, 2)\n",
      "(5, 2)\n",
      "(5, 2)\n",
      "(5, 2)\n",
      "(5, 2)\n",
      "(5, 2)\n",
      "(6, 2)\n",
      "(6, 2)\n",
      "(6, 2)\n",
      "(6, 2)\n",
      "(6, 2)\n",
      "(6, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.        , 0.69680259],\n       [0.69680259, 0.7555514 ],\n       [0.7555514 , 0.99597873],\n       [0.99597873, 0.9972507 ],\n       [0.9972507 , 0.99912933],\n       [0.99912933, 0.99965211],\n       [0.99965211, 0.99971676],\n       [0.99971676, 0.99971984],\n       [0.99971984, 0.99993107],\n       [0.99993107, 0.99999218],\n       [0.99999218, 0.9999962 ],\n       [0.9999962 , 1.        ]])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Data.GeneratorOfAvailableTimeslots import GeneratorOfAvailableTimeslots\n",
    "\n",
    "time_slots_gen = GeneratorOfAvailableTimeslots(5)\n",
    "time_slots = time_slots_gen.generate_available_timeslots()\n",
    "\n",
    "time_slots      # TODO: why all the intervals are closed?\n",
    "\n",
    "# TODO THIS IS ONLY FOR TESTING\n",
    "single_interval = time_slots[0]\n",
    "single_interval"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-02T02:27:33.598118Z",
     "end_time": "2023-07-02T02:27:33.642715Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Init the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# check if the dataloader works and get the input and output sizes\n",
    "in_features = 0\n",
    "out_features = 0\n",
    "for i, (features, _, ans) in enumerate(train_dataloader):\n",
    "    in_features = features.shape[1]\n",
    "    out_features = 3             # TODO: change to ans.shape[1]\n",
    "    break\n",
    "\n",
    "n_layers = 1\n",
    "hidden_size = 30\n",
    "\n",
    "# Create the model\n",
    "SC_LSTM = Model(in_features, n_layers, hidden_size, out_features, batch_size).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-02T02:27:33.640528Z",
     "end_time": "2023-07-02T02:27:33.658443Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# Configure hyper-parameters\n",
    "epochs = 1\n",
    "learning_rate = 0.001\n",
    "loss_func = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(SC_LSTM.parameters(), lr=learning_rate)\n",
    "\n",
    "history = []\n",
    "loss_accomulator = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-02T02:27:33.660025Z",
     "end_time": "2023-07-02T02:27:33.741284Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            6.28it/s]\r"
     ]
    }
   ],
   "source": [
    "# Firstly train the LSTM using only reschedulable tasks\n",
    "SC_LSTM.train()\n",
    "SC_LSTM.train_lstm()\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    for i, (X, task_type, Y) in enumerate(tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\", leave=False, colour='green')):\n",
    "\n",
    "        # Convert X to the correct type\n",
    "        X = torch.Tensor(X).type(torch.float32)\n",
    "\n",
    "        # Forward only for reschedulable tasks\n",
    "        if task_type[0] == \"resched\":\n",
    "\n",
    "            Y_pred = SC_LSTM.forward(X, task_type=task_type, free_time_slots=single_interval).to(device)\n",
    "\n",
    "\n",
    "        # # Calculate loss\n",
    "        # loss = loss_func(Y_pred.view(-1, ), Y.view(-1, ))\n",
    "        #\n",
    "        # # Backward pass\n",
    "        # loss.backward(retain_graph=True)\n",
    "        # optimizer.step()\n",
    "        # optimizer.zero_grad()\n",
    "        #\n",
    "        # # Append loss to list\n",
    "        # loss_accomulator.append(loss.item())\n",
    "        #\n",
    "        # history.append(np.mean(loss_accomulator))\n",
    "        # loss_accomulator = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-02T02:27:33.741156Z",
     "end_time": "2023-07-02T02:27:34.020604Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Configure hyper-parameters\n",
    "epochs = 1\n",
    "learning_rate = 0.001\n",
    "loss_func = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(SC_LSTM.parameters(), lr=learning_rate)\n",
    "\n",
    "history = []\n",
    "loss_accomulator = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-02T02:27:34.026683Z",
     "end_time": "2023-07-02T02:27:34.068460Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                ?, ?it/s]\r"
     ]
    }
   ],
   "source": [
    "# Now train the injector using non-reschedulable tasks\n",
    "SC_LSTM.train()\n",
    "SC_LSTM.train_injector()\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    for i, (X, task_type, Y) in enumerate(tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\", leave=False, colour='green')):\n",
    "\n",
    "        # Convert X to the correct type\n",
    "        X = torch.Tensor(X).type(torch.float32)\n",
    "\n",
    "        # Forward only for non-reschedulable tasks\n",
    "        if task_type[0] == \"non-resched\":\n",
    "\n",
    "            Y_pred = SC_LSTM.forward(X, task_type=task_type, free_time_slots=single_interval).to(device)\n",
    "\n",
    "\n",
    "            #TODO how to convert X to Y ~ (start, end, refr)\n",
    "            # # Calculate loss\n",
    "            # loss = loss_func(Y_pred.view(-1, ), Y.view(-1, ))\n",
    "            #\n",
    "            # # Backward pass\n",
    "            # loss.backward(retain_graph=True)\n",
    "            # optimizer.step()\n",
    "            # optimizer.zero_grad()\n",
    "            #\n",
    "            # # Append loss to list\n",
    "            # loss_accomulator.append(loss.item())\n",
    "            #\n",
    "            # history.append(np.mean(loss_accomulator))\n",
    "            # loss_accomulator = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-02T02:41:04.740694Z",
     "end_time": "2023-07-02T02:41:04.836320Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
